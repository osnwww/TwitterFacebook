# -*- coding: utf-8 -*-
# this is used to create the function: isSameUrl(url1,url2), which can identify whether two long URLs are the same
# the output (userSameUrlCount) is useless.

# Problem when comparing two long URLs are the same.
# for Twitter ID 17229160, whose facebook ID is 63830851925
# URL in Twitter is: http://www.elconfidencial.com/mundo/2016-03-25/identifican-a-una-espanola-entre-las-victimas-de-los-atentados-de-bruselas_1174381/?utm_source=dlvr.it&utm_medium=twitter
# Url in Facebook  : http://www.elconfidencial.com/mundo/2016-03-25/identifican-a-una-espanola-entre-las-victimas-de-los-atentados-de-bruselas_1174381/
# although it is the same webpages, but the URL is different.
#url1 = 'http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=tw-nytimes&smtyp=cur&_r=0'
#url2 = 'http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=fb-nytimes&smtyp=cur&_r=0'

# input1: userSameUrlCountSelect    # generated by 1UserSameUrlCount
# TwitterUser  #follower  #twitterUrl  #sameUrl    FacebookUser  #likes  #facebookUrl accountType           	twittername     Facebookname
# 14124402	    38131	21  	    1	    303931369704301   11597	14        FacebookFromTwitterProfiles	pedrodoria	pdoria
#    0           1          2           3             4            5        6              7                            8             9

# input2: expandDnsTwitterData
# shortURL                               longURL                                       status
# http://bit.ly/1Ux1bFx	https://amp.twimg.com/v/77996099-1089-4371-944d-3e863875fd7b	200
# http://www.warnerchannel.com	http://www.warnerchannel.com/co/	200

# input3: expandDnsFacebookData
# input4: formatTweets
#     userID  #ReTweet  #favorite   createdTime       shortURL
# |::|19364233|::|11|::|12|::|2016-03-31 17:58:43|::|http://bit.ly/1UviOVP|;;|
# |::|19364233|::|2|::|4|::|2016-03-31 16:01:17|::|http://www.offbeat.com/yeah-right/|;;|

# input5: formatFeeds

# output: userSameUrlCount:
# TwitterUser  #follower  #twitterUrl  #sameUrl    FacebookUser  #likes  #facebookUrl
# 14124402	38131	    21  	1	303931369704301	  11597	    14
#    0           1          2           3             4            5        6

import urllib2
import urllib
import cookielib
import re
import datetime
import time
import sys
import os
import traceback
from urllib2 import HTTPError, Request, urlopen, URLError

import difflib

#import adodbapi
#import minjson

def printTime(beginTime):
    endTime = datetime.datetime.now() #calculate time
    print ("------------consumed-----------time-----------begin-----------")
    print ("consumed time:" + str(endTime - beginTime) )
    print ("------------consumed-----------time-----------end-------------")
    
def clearUrlYouTube(url1):
    #reYouTube = re.compile(r'IndexRedirect\?continue=https://www.youtube.com/watch%3Fv%3D(.+?)%26feature',re.S)
    reYouTube = re.compile(r'://www.youtube.com/watch%3Fv%3D(.+?)[%&]',re.S)
    #https://ipv4.google.com/sorry/IndexRedirect?continue=https://www.youtube.com/watch%3Fv%3DTrNWpXUJRFw%26feature%3Dyoutu.be&q=CGMSBK6LC44Y88KFuQUiGQDxp4NLAmem-K3bW-k-haSiyoJMk-ceR2w
    #https://ipv4.google.com/sorry/IndexRedirect?continue=https://www.youtube.com/watch%3Fv%3DTrNWpXUJRFw%26feature%3Dyoutu.be&q=CGMSBK6LC44Y-9CQuQUiGQDxp4NLtD_pu4QYa1BkINmWpZ3IksJ6EMI
    #                                                         https://www.youtube.com/watch?v=TrNWpXUJRFw
    #https://ipv4.google.com/sorry/IndexRedirect?continue=https://www.youtube.com/watch%3Fv%3D5Xn-LvQH79I&q=CGMSBK6LC44YjLyGuQUiGQDxp4NLvI2zknswSZi4ObGAhAPfN_-sPBg
    #                                                         https://www.youtube.com/watch?v=5Xn-LvQH79I
    #http ://ipv4.google.com/sorry/IndexRedirect?continue=http://www.youtube.com/watch%3Fv%3DcwXfv25xJUw%26sns%3Dfb&q=CGMSBK6LC44Yk8H7uAUiGQDxp4NLuAQmgwSbNJIRxx4BWn0jsxK2cGY
    clearUrl = url1
    youtubeList = reYouTube.findall(url1)
    if(len(youtubeList) >= 1):
        clearUrl = "https://www.youtube.com/watch?v=" + youtubeList[0] 
        #print curL[1]
        #print longUrl
    #print url1
    #print clearUrl
    return clearUrl
def clearUrlUtm(url1):
    # clear utm_source=***&utm_medium=****&utm_campaign=******    
    # Google Analytics::  https://support.google.com/analytics/answer/1033867?hl=zh-Hans    # utm_source utm_medium utm_term utm_content utm_campaign
    
    # Twitter URL : http://www.elconfidencial.com/mundo/2016-03-25/identifican-a-una-espanola-entre-las-victimas-de-los-atentados-de-bruselas_1174381/?utm_source=dlvr.it&utm_medium=twitter
    # Facebook URL: http://www.elconfidencial.com/mundo/2016-03-25/identifican-a-una-espanola-entre-las-victimas-de-los-atentados-de-bruselas_1174381/ 
    #78684416 BlogdoJuca
    #http://blogdojuca.uol.com.br/2016/04/romario-responde-a-renan/
    #http://blogdojuca.uol.com.br/2016/04/romario-responde-a-renan/?utm_source=dlvr.it&utm_medium=facebook    
    #634330366
    #http://reagancoalition.com/articles/2016/heres-a-test-experts-claim-only-people-with-perfect-vision-can-pass-think-you-can-pass-it-try-it-now.html
    #http://reagancoalition.com/articles/2016/heres-a-test-experts-claim-only-people-with-perfect-vision-can-pass-think-you-can-pass-it-try-it-now.html?utm_source=fnot1&utm_medium=facebook
    #twitter: 14075928; TheOnion
    #http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642
    #http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642?utm_medium=RSS&utm_campaign=feeds   
    
    #http://www.radionica.rocks/noticias/las-11-de-acdc?utm_content=buffer3f962&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer
    #http://www.radionica.rocks/noticias/las-11-de-acdc?utm_content=buffer8783e&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer      
    
    re1 = re.compile(r'utm_source(.+?)&',re.S)
    re2 = re.compile(r'utm_medium(.+?)&',re.S)
    re3 = re.compile(r'utm_term(.+?)&',re.S)
    re4 = re.compile(r'utm_content(.+?)&',re.S)
    re5 = re.compile(r'utm_campaign(.+?)&',re.S)
    url2 = url1 + '&'
    url2 = re1.sub('',url2 )
    url2 = re2.sub('',url2 )
    url2 = re3.sub('',url2 )
    url2 = re4.sub('',url2 )
    url2 = re5.sub('',url2 )
    if(url2[len(url2)-1:]=='?'):
        url2 = url2[:len(url2)-1]
    if(url2[len(url2)-1:]=='&'):
        url2 = url2[:len(url2)-1]
        
    clearUrl = url2
    #print url1
    #print clearUrl
    return clearUrl
def clearUrlHtml(url1):
    # identify same URLs like below
    #twitter: 44376439;GloboLivros
    #url1 = 'http://pipanaosabevoar.blogspot.com.br/2016/03/historia-do-novo-sobrenome-carta-para.html?platform=hootsuite'
    #url1 = 'http://pipanaosabevoar.blogspot.com.br/2016/03/historia-do-novo-sobrenome-carta-para.html
   
    #http://www.posta.com.tr/turkiye/HaberDetay/Diyarbakir-da-siddetli-patlama.htm?ArticleID=335112
    #http://www.posta.com.tr/turkiye/HaberDetay/Diyarbakir-da-siddetli-patlama.htm
    
    #twitter: 35525950; Affaritaliani
    #http://www.affaritaliani.it/politica/forza-italia-senza-soldi-413229.html
    #http://www.affaritaliani.it/politica/forza-italia-senza-soldi-413229.html?ref=rss
    
    # Twitter:16455997;  FB: 43730674468; Tweets:468, common:116, feeds:677
    # http://www.local8now.com/content/news/Board-of-Education-member-to-host-community-meeting-following-school-threats-373786391.html?utm_medium=social&utm_source=twitter_wvlt
    # http://www.local8now.com/content/news/Board-of-Education-member-to-host-community-meeting-following-school-threats-373786391.html
    
    #http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html?sr=twcnni041116u-s-in-iraq-isis-fight0453PMStoryLink&linkId=23322553
    #http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html        
    clearUrl = url1
    htmlPos = url1.find('.html?')
    if(htmlPos > 0 ):
        clearUrl = url1[:htmlPos+5]
        
    htmlPos = url1.find('.htm?')
    if(htmlPos > 0 ):
        clearUrl = url1[:htmlPos+4]
    #print url1
    #print clearUrl
    return clearUrl    
def clearHashMar(url1):
    #----------------difference is after #-----------------------begin-----------------------------
    #twitter: 18847469;Tennis
    #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWYXGOprFI
    #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWEYcfJcYk
    #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWEt8fJcYk
    #31206077 johnmcdougallmd
    #https://medium.com/@davidludwigmd/declining-life-expectancy-according-to-new-cdc-data-d137ae07d1bb#.fzvb0yd58
    #https://medium.com/@davidludwigmd/declining-life-expectancy-according-to-new-cdc-data-d137ae07d1bb
    '''
    posHashMark = url1.find('#')
    posHashMark2 = url2.find('#')
    #posHashMark = url1.find('?')
    #posHashMark2 = url2.find('?')
    if(posHashMark > 0 or  posHashMark2 > 0):
        twitterUrl2 = url1
        if(posHashMark > 0):
            twitterUrl2 = url1[:posHashMark]
        facebookUrl2 = url2
        if(posHashMark2 > 0):
            facebookUrl2 = url2[:posHashMark2]
        if(twitterUrl2 == facebookUrl2):
            isSame = 1
            return (isSame,twitterUrl2)
    '''
    #----------------difference is after #-----------------------end-------------------------------
    posHashMark = url1.find('#')
    clearUrl = url1
    if(posHashMark > 0):
        clearUrl = url1[:posHashMark]    
    return clearUrl 
def isSameUrl(url1,url2):
 
    #url1 = 'http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=twcnni040216portuguese-artist-vhils-hong-kong1200AMVODtopLink&linkId=22941723'
    #url2 = 'http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=fbcnni032416portuguese-artist-vhils-hong-kong0815AMVODtopLink&linkId=22636851'

    #url1 = 'http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=tw-nytimes&smtyp=cur&_r=0'
    #url2 = 'http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=fb-nytimes&smtyp=cur&_r=0'

    #url1 = 'http://pipanaosabevoar.blogspot.com.br/2016/03/historia-do-novo-sobrenome-carta-para.html?platform=hootsuite'
    #url2 = 'http://pipanaosabevoar.blogspot.com.br/2016/03/historia-do-novo-sobrenome-carta-para.html'
    
    #url1 = 'http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642'
    #url2 = 'http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642?utm_medium=RSS&utm_campaign=feeds'
    
    isSame = 0
    
    url1 = url1.lower()
    url2 = url2.lower()
    urlLen1 = len(url1)
    urlLen2 = len(url2)
    
    #---------------------difference is the "twitter facebook"(tw fb) and number----------------------begin-----------------------
    #http://action.bornthisway.foundation/page/s/kindness-pledge-nominate?source=BKG_KindMonsters&subsource=BKG_Platform_Twitter
    #http://action.bornthisway.foundation/page/s/kindness-pledge-nominate?source=BKG_KindMonsters&subsource=BKG_Platform_Facebook

    #http://www.cnn.com/2016/04/08/opinions/bill-clinton-black-lives-matter-protesters-opinion-garza/index.html?sr=twCNN040816bill-clinton-black-lives-matter-protesters-opinion-garza1106PMVODtopLink&linkId=23262300        
    #http://www.cnn.com/2016/04/08/opinions/bill-clinton-black-lives-matter-protesters-opinion-garza/index.html?sr=fbCNN040916bill-clinton-black-lives-matter-protesters-opinion-garza1232AMVODtopLink&linkId=23264009

    #http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=twcnni032516portuguese-artist-vhils-hong-kong0640AMVODtopLink&linkId=22676871
    #http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=twcnni032416portuguese-artist-vhils-hong-kong0815AMVODtopLink&linkId=22636854
    #http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=twcnni040216portuguese-artist-vhils-hong-kong1200AMVODtopLink&linkId=22941723
    #http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=fbcnni032416portuguese-artist-vhils-hong-kong0815AMVODtopLink&linkId=22636851
    #http://www.cnn.com/2016/03/24/arts/portuguese-artist-vhils-hong-kong/index.html?sr=fbcnni040216portuguese-artist-vhils-hong-kong1200AMVODtopLink&linkId=22941725

    #http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=tw-nytimes&smtyp=cur&_r=0
    #http://www.nytimes.com/2016/03/21/world/europe/russian-town-says-bleak-depictionin-leviathan-film-went-heavy-on-the-vodka.html?smid=fb-nytimes&smtyp=cur&_r=0


    if(urlLen1 == urlLen2):
        diffString1 = ''
        diffString2 = ''
        for i in range(0,urlLen1):
            if(url1[i] != url2[i]):
                if(url1[i].isdigit() and url2[i].isdigit()):
                    continue
                diffString1 += url1[i]
                diffString2 += url2[i]
        if((diffString1 == 'tw' or diffString1 == 'fb') and (diffString2 == 'tw' or diffString2 == 'fb')):
            #print diffString1
            #print diffString2
            isSame = 1
    #---------------------difference is the "twitter facebook"(tw fb) and number----------------------end-------------------------
    
    #---------------------difference is the "twitter facebook"(social_twitter social_facebook) and number----------------------begin-----------------------
    #url1 = 'http://www.theonion.com/article/increasing-number-of-couples-now-using-surrogates--38509?utm_content=Main&utm_campaign=SF&utm_source=Facebook&utm_medium=SocialMarketing'
    #url2 = 'http://www.theonion.com/article/increasing-number-of-couples-now-using-surrogates--38509?utm_content=Main&utm_campaign=SF&utm_source=Twitter&utm_medium=SocialMarketing'
    
    #url1 = 'http://www.newyorker.com/culture/photo-booth/joyful-forms-the-little-known-photography-of-ellsworth-kelly?mbid=social_twitter'
    #url2 = 'http://www.newyorker.com/culture/photo-booth/joyful-forms-the-little-known-photography-of-ellsworth-kelly?mbid=social_facebook'
 
 
    elif(abs(urlLen1 - urlLen2) == 1):
        url1r = url1.replace('twitter','facebook')
        url2r = url2.replace('twitter','facebook')
        if(len(url1r) == len(url2r)):
            diffString1 = ''
            diffString2 = ''
            for i in range(0,len(url1r)):
                if(url1r[i] != url2r[i]):
                    if(url1r[i].isdigit() and url2r[i].isdigit()):
                        continue
                    diffString1 += url1r[i]
                    diffString2 += url2r[i]
            if((diffString1 == '' and diffString2 == '')):
                isSame = 1
    #---------------------difference is the "twitter facebook"(social_twitter social_facebook) and number----------------------end-------------------------
   
    
    
    #----------------difference is after ?-----------------------begin-----------------------------
    '''
    #------------below Urls are the same------------------------
    #20760637
    #https://www.eventbrite.co.uk/e/inspired-by-science-women-tell-their-stories-tickets-21255306193?ref=estw
    #https://www.eventbrite.co.uk/e/inspired-by-science-women-tell-their-stories-tickets-21255306193
    
    # http://advice.careerbuilder.com/posts/20-gifs-that-accurately-depict-what-its-like-to-be-a-job-seeker?linkId=22927371 
    # http://advice.careerbuilder.com/posts/20-gifs-that-accurately-depict-what-its-like-to-be-a-job-seeker

    #http://arstechnica.com/science/2016/03/looks-aside-nasas-orion-is-lightyears-ahead-of-what-they-had-in-apollo/?mbid=social_cp_twitter_tny
    #http://arstechnica.com/science/2016/03/looks-aside-nasas-orion-is-lightyears-ahead-of-what-they-had-in-apollo/

    #http://artsbeat.blogs.nytimes.com/2016/03/28/broadway-enjoys-a-spring-fling-at-the-box-office/?smid=tw-nyttheater&smtyp=cur&_r=0
    #http://artsbeat.blogs.nytimes.com/2016/03/28/broadway-enjoys-a-spring-fling-at-the-box-office/

    #http://birdsandblooms.com/blog/spring-flowers-in-a-carnivorous-plants-bog/?trkid=TWITTER_BNB_20160402_Flowers_Spring_BlogPost
    #http://birdsandblooms.com/blog/spring-flowers-in-a-carnivorous-plants-bog/
    
    
    #---------------below Urls are different-----------this code cannot solve this problem-------------------------
    #http://abcnews.go.com/Business/judges-ruling-law-school-grads-debt-signal-seismic/story?id=37981518   
    #http://abcnews.go.com/Business/judges-ruling-law-school-grads-debt-signal-seismic/story

    #http://digitaledition.baltimoresun.com/launch.aspx?pbid=99644e1a-52da-4fe3-8f78-a84e4fe4d386
    #http://digitaledition.baltimoresun.com/launch.aspx    
    
    elif(abs(urlLen1 - urlLen2) >= 3):
        isReplace = 0
        url1Left = url1.replace(url2,'')
        url2Left = url2.replace(url1,'')
        if(len(url1Left) < len(url1)):
            if(url1Left[:1] == '?'):
                #print url1
                #print url2 
                isSame = 1
        elif(len(url2Left) < len(url2)):
            if(url2Left[:1] == '?'):
                #print url1
                #print url2   
                isSame = 1
    #----------------difference is after ?-----------------------end-------------------------------    
    '''
    
    '''
    #----------------difference is a few characters-----------------------begin-----------------------------
    #below examples are not good, because these URLs end up with .html, which have been cleared by clearUrlHtml(url1)

    #repeat: 18730977; radionica
    #http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html?sr=twcnni041116u-s-in-iraq-isis-fight0453PMStoryLink&linkId=23322553
    #http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html?sr=fbcnni041116u-s-in-iraq-isis-fight0455PMVODtopLink&linkId=23322424
    
    #http://www.cnn.com/2016/03/21/politics/raul-castro-political-prisoners/index.html?sr=fbCNN032216raul-castro-political-prisoners0416AMVODtopLink&linkId=22537860
    #http://www.cnn.com/2016/03/21/politics/raul-castro-political-prisoners/index.html?sr=twCNN032216raul-castro-political-prisoners0324AMVODtopPhoto&linkId=22537233

    #http://www.nytimes.com/2016/04/02/us/pro-trump-chalk-messages-cause-conflicts-on-college-campuses.html?smid=tw-nytimes&smtyp=cur&_r=0
    #http://www.nytimes.com/2016/04/02/us/pro-trump-chalk-messages-cause-conflicts-on-college-campuses.html?smid=fb-nytimes&smtyp=cur
    
    
    if(isSame == 0 and abs(urlLen1 - urlLen2) <= 10 and urlLen1 > 90 and urlLen2 > 90 ):
        posQuestion11 = url1.find('?')
        posQuestion22 = url2.find('?')
        extractUrl11 = url1
        extractUrl22 = url2
        if(posQuestion11 > 0):
            extractUrl11 = url1[:posQuestion11]
        if(posQuestion22 > 0):
            extractUrl22 = url2[:posQuestion22]
        if(extractUrl11 == extractUrl22):
            diff = difflib.ndiff(url1, url2,linejunk=None)
            diff2 = list(diff)
            only1 = ''
            only2 = ''
            for i in range(0,len(diff2)):
                if(diff2[i][0] == '-'):
                    only1 +=  diff2[i][2]
                elif(diff2[i][:1] == '+'):
                    only2 +=  diff2[i][2] 
            #print 'only1:' + only1
            #print 'only2:' + only2
            if( float(len(only1))/urlLen1 < 0.1 and float(len(only2))/urlLen2  < 0.1):
                    isSame = 1
            
     #----------------difference is a few characters-----------------------end-----------------------------
     '''
    extractUrl = url1
    if(isSame == 1):
            posQuestion = url1.find('?')
            posQuestion2 = url2.find('?')
            if(posQuestion > 0):
                extractUrl = url1[:posQuestion]
            elif(posQuestion2 > 0):
                extractUrl = url2[:posQuestion2]

    return (isSame,extractUrl)

    #-------------don't deal with---------------------begin-----------------------------------
    #twitter: 106308661;arjunmodhwadia
    #http://economictimes.indiatimes.com/news/politics-and-nation/gujarat-farmer-burnt-alive-over-loan-given-by-moneylender/articleshow/51566299.cms?from=mdr
    #         http://m.economictimes.com/news/politics-and-nation/gujarat-farmer-burnt-alive-over-loan-given-by-moneylender/articleshow/51566299.cms  

    #25093616
    #http://www.menshealth.com/fitness/stop-wasting-time?cid=soc_MensHealthMag_TWITTER_Men%27s%20Health__
    #http://www.menshealth.com/fitness/stop-wasting-time?cid=soc_Men%27s%20Health%20-%20MensHealth_FBPAGE_Men%27s%20Health__

    
    #-------------don't deal with---------------------end--------------------------------------
    
    #http://www.nytimes.com/2016/04/08/fashion/mens-style/john-colapinto-literary-sex-novel-undone.html?smid=fb-nytimes&smtyp=cur
    #http://www.nytimes.com/2016/04/08/fashion/mens-style/john-colapinto-literary-sex-novel-undone.html?contentCollection=weekendreads&smid=tw-nytimes&smtyp=cur&_r=0    
    
def readExpandDns(inFile2,twitterExpandUrl):
    
    fileCount = 0
    for root, dirs, files in os.walk(inFile2):
        for name in files:
            fileCount += 1
            print str(fileCount) + '::currentFile::' + name
            fileName = os.path.join(root, name)
            fin = open(fileName)
            # shortURL                               longURL                                       status
            # http://bit.ly/1Ux1bFx	https://amp.twimg.com/v/77996099-1089-4371-944d-3e863875fd7b	200
            # http://www.warnerchannel.com	http://www.warnerchannel.com/co/	200
            for current in fin:
                current2 = current.replace('\n','')
                curL= current2.split('\t')
                shortUrl = curL[0]
                longUrl = curL[1]
                status = curL[2]
                if(not twitterExpandUrl.has_key(shortUrl)):
                    longUrl = clearUrlYouTube(longUrl)
                    longUrl = clearUrlHtml(longUrl)
                    longUrl = clearUrlUtm(longUrl)
                    longUrl = clearHashMar(longUrl)

                    twitterExpandUrl[shortUrl] = longUrl
                else:
                    if(status != '404'):
                        twitterExpandUrl[shortUrl] = longUrl
    print 'len(twitterExpandUrl):' + str(len(twitterExpandUrl))

def readFormatTweets(inFile4, TwitterUserUrl,twitterExpandUrl):
    #     userID  #ReTweet  #favorite   createdTime       shortURL
    # |::|19364233|::|11|::|12|::|2016-03-31 17:58:43|::|http://bit.ly/1UviOVP|;;|
    # |::|19364233|::|2|::|4|::|2016-03-31 16:01:17|::|http://www.offbeat.com/yeah-right/|;;|    
    fin = open(inFile4)
    columnMark =  '|::|'
    rowMark = '|;;|\n'
    count =0
    for current in fin:
        data = current[4:-5]
        curL = data.split(columnMark)
        userID = curL[0]
        shortUrl = curL[4]
        expandurl  = twitterExpandUrl[shortUrl]
        
        if(expandurl.find('twitter.com') >= 0):  # only select the third websites
            continue   
        if(expandurl.find('facebook.com') >= 0): # only select the third websites
            continue
        
        if(not TwitterUserUrl.has_key(userID)):
            TwitterUserUrl[userID] = {}
        if(not TwitterUserUrl[userID].has_key(expandurl)):
            TwitterUserUrl[userID][expandurl] = 1
        else:
            TwitterUserUrl[userID][expandurl] += 1
    print 'len(TwitterUserUrl):' + str(len(TwitterUserUrl))

def readUserPair(inFile,outFile,TwitterUserUrl,FacebookUserUrl):
    
    fout = open(outFile,'w')
    fin = open(inFile)                        
    # TwitterUser  #follower  #twitterUrl  #sameUrl    FacebookUser  #likes  #facebookUrl accountType           	twittername     Facebookname
    # 14124402	    38131	21  	    1	    303931369704301   11597	14        FacebookFromTwitterProfiles	pedrodoria	pdoria
    #    0           1          2           3             4            5        6              7                            8             9
    count =0
    selectCount = 0
    for current in fin:
        count += 1
        if(count %10 == 0):
            print count
        data = current.replace('\n','')
        curL = data.split('\t')
        twitterID = curL[0]
        facebookID = curL[4]
        
        if(twitterID != '807095'):
            continue


        if(not TwitterUserUrl.has_key(twitterID)):
            continue
        if(not FacebookUserUrl.has_key(facebookID)):
            continue 
            
        sameUrlCount = 0
        writedTwitterUrl = {}
        writedFacebookUrl = {}
        writedTwitterUrlRepeat = {}
        writedFacebookUrlRepeat = {}
        for(twitterUrl,twitterUrlCount) in TwitterUserUrl[twitterID].items():
            for(facebookUrl,facebookUrlCount) in FacebookUserUrl[facebookID].items():     
                if(twitterUrl == facebookUrl):
                    writedTwitterUrl[twitterUrl] = 1
                    writedFacebookUrl[facebookUrl] = 1
                    
                    if(not writedTwitterUrlRepeat.has_key(twitterUrl)):
                        writedTwitterUrlRepeat[twitterUrl] = 1
                    else:
                        writedTwitterUrlRepeat[twitterUrl] += 1
                        continue
                    if(not writedFacebookUrlRepeat.has_key(facebookUrl)):
                        writedFacebookUrlRepeat[facebookUrl] = 1
                    else:
                        writedFacebookUrlRepeat[facebookUrl] += 1
                        continue
                    
                    sameUrlCount += 1
                    fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(facebookUrl) + '\n')
                else:
                    (isSame,extractUrl) = isSameUrl(twitterUrl,facebookUrl)
                    if(isSame == 1):  
                        writedTwitterUrl[twitterUrl] = 1
                        writedFacebookUrl[facebookUrl] = 1
                        if(not writedTwitterUrlRepeat.has_key(extractUrl)):
                            writedTwitterUrlRepeat[extractUrl] = 1
                        else:
                            writedTwitterUrlRepeat[extractUrl] += 1
                            continue
                        if(not writedFacebookUrlRepeat.has_key(extractUrl)):
                            writedFacebookUrlRepeat[extractUrl] = 1
                        else:
                            writedFacebookUrlRepeat[extractUrl] += 1
                            continue     
                        
                        sameUrlCount += 1
                        fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(facebookUrl) + '\n')  
                        
        for(twitterUrl,twitterUrlCount) in TwitterUserUrl[twitterID].items():
            if(not writedTwitterUrl.has_key(twitterUrl)):
                fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(0) + '\n')
        for(facebookUrl,facebookUrlCount) in FacebookUserUrl[facebookID].items(): 
            if(not writedFacebookUrl.has_key(facebookUrl)):
                fout.write(data + '\t'  + str(0) + '\t'  + str(facebookUrl) + '\n')
def main(argv):
    
    inFile = argv[1]   # userSameUrlCountSelect # generate by 1userSameUrlCountForIdentifSameUrl
    inFile2 = argv[2]  # expandDnsTwitterData
    inFile3 = argv[3]  # expandDnsFacebookData
    inFile4 = argv[4]  # formatTweets
    inFile5 = argv[5]  # formatFeeds
    outFile = argv[6]  # userSameUrlCountBothURLs

    reload(sys)
    sys.setdefaultencoding('utf-8')
    beginTime = datetime.datetime.now() 
    '''
    url1 = 'http://www.worldsurfleague.com/posts/190818/fanning-firing-as-mens-commences-at-bells-day-2-recap?utm_campaign=Bells_2016&utm_source=Social&utm_medium=Facebook&utm_term=Editorial+Link&utm_content=Bells+Recap'
    #url1 = 'http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642'
    #url1 = 'http://www.newyorker.com/culture/photo-booth/joyful-forms-the-little-known-photography-of-ellsworth-kelly?mbid=social_twitter'  
    url1 = 'http://reagancoalition.com/articles/2016/heres-a-test-experts-claim-only-people-with-perfect-vision-can-pass-think-you-can-pass-it-try-it-now.html?utm_source=fnot1&utm_medium=facebook'
    url2 = clearUrlHtml(url1)
    url2 = clearUrlUtm(url2)
    return
    '''
    
    twitterExpandUrl = {} # twitterExpandUrl[shortUrl] = expandUrl
    readExpandDns(inFile2,twitterExpandUrl)
    facebookExpandUrl = {} # facebookExpandUrl[shortUrl] = expandUrl
    readExpandDns(inFile3,facebookExpandUrl)
    
    TwitterUserUrl = {} # TwitterUserUrl[userid][expandUrl] = 1
    readFormatTweets(inFile4, TwitterUserUrl,twitterExpandUrl)
    FacebookUserUrl = {} # FacebookUserUrl[userid][expandUrl] = 1
    readFormatTweets(inFile5, FacebookUserUrl,facebookExpandUrl)
    
    readUserPair(inFile,outFile,TwitterUserUrl,FacebookUserUrl)    
    
    '''
    
    twitterUrl = 'http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html?sr=twcnni041116u-s-in-iraq-isis-fight0453PMStoryLink&linkId=23322553'
    facebookUrl = 'http://edition.cnn.com/2016/04/10/middleeast/u-s-in-iraq-isis-fight/index.html'
    (isSame,extractUrl) = isSameUrl(twitterUrl,facebookUrl)
    print isSame
    print extractUrl
    '''

    printTime(beginTime)       
    print "\a"
    print 'finish' 
    
    
    
    '''
    isSame = 0
    url1 = 'http://www.cnn.com/2016/03/21/politics/raul-castro-political-prisoners/index.html?sr=fbCNN032216raul-castro-political-prisoners0416AMVODtopLink&linkId=22537860'
    url2 = 'http://www.cnn.com/2016/03/21/politics/raul-castro-political-prisoners/index.html?sr=twCNN032216raul-castro-political-prisoners0324AMVODtopPhoto&linkId=22537233'
    urlLen1 = len(url1)
    urlLen2 = len(url2)
    if(isSame == 0 and abs(urlLen1 - urlLen2) <= 2 and urlLen1 > 90 and urlLen2 > 90 ):
        print url1
        posQuestion11 = url1.find('?')
        posQuestion22 = url2.find('?')
        extractUrl11 = url1
        extractUrl22 = url2
        if(posQuestion11 > 0):
            extractUrl11 = url1[:posQuestion11]
        if(posQuestion22 > 0):
            extractUrl22 = url2[:posQuestion22]
        if(extractUrl11 == extractUrl22):
            diff = difflib.ndiff(url1, url2,linejunk=None)
            diff2 = list(diff)
            only1 = ''
            only2 = ''
            for i in range(0,len(diff2)):
                if(diff2[i][0] == '-'):
                    only1 +=  diff2[i][2]
                elif(diff2[i][:1] == '+'):
                    only2 +=  diff2[i][2] 
            print 'only1:' + only1
            print 'only2:' + only2
            if( float(len(only1))/urlLen1 < 0.1 and float(len(only2))/urlLen2  < 0.1):
                    isSame = 1
                    
     '''

    
if __name__ == "__main__":
    #Ö´main fuction
    main(sys.argv)


'''
def readUserPair(inFile,outFile,TwitterUserUrl,FacebookUserUrl):
    
    fout = open(outFile,'w')
    fin = open(inFile)                        
    # TwitterUser  #follower  #twitterUrl  #sameUrl    FacebookUser  #likes  #facebookUrl accountType           	twittername     Facebookname
    # 14124402	    38131	21  	    1	    303931369704301   11597	14        FacebookFromTwitterProfiles	pedrodoria	pdoria
    #    0           1          2           3             4            5        6              7                            8             9
    count =0
    selectCount = 0
    for current in fin:
        count += 1
        if(count %1000 == 0):
            print count
        data = current.replace('\n','')
        curL = data.split('\t')
        twitterID = curL[0]
        facebookID = curL[4]
        
        #if(twitterID != '18730977'):
        #    continue
        
        
        #----------------difference is after #-----------------------begin-----------------------------
        #twitter: 18847469;Tennis
        #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWYXGOprFI
        #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWEYcfJcYk
        #http://www.tennis.com/pro-game/2016/03/federers-return-from-knee-surgery-delayed-by-stomach-virus/57964/#.VvWEt8fJcYk
        #31206077 johnmcdougallmd
        #https://medium.com/@davidludwigmd/declining-life-expectancy-according-to-new-cdc-data-d137ae07d1bb#.fzvb0yd58
        #https://medium.com/@davidludwigmd/declining-life-expectancy-according-to-new-cdc-data-d137ae07d1bb
        #----------------difference is after #-----------------------end-------------------------------
        
        #twitter: 106308661;arjunmodhwadia
        #http://economictimes.indiatimes.com/news/politics-and-nation/gujarat-farmer-burnt-alive-over-loan-given-by-moneylender/articleshow/51566299.cms?from=mdr
        #         http://m.economictimes.com/news/politics-and-nation/gujarat-farmer-burnt-alive-over-loan-given-by-moneylender/articleshow/51566299.cms     
    
        #repeat: 18730977; radionica
        #http://www.radionica.rocks/noticias/las-11-de-acdc?utm_content=buffer3f962&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer
        #http://www.radionica.rocks/noticias/las-11-de-acdc?utm_content=buffer8783e&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer

        if(not TwitterUserUrl.has_key(twitterID)):
            continue
        if(not FacebookUserUrl.has_key(facebookID)):
            continue 
            
        sameUrlCount = 0
        writedTwitterUrl = {}
        writedFacebookUrl = {}
        writedTwitterUrlRepeat = {}
        writedFacebookUrlRepeat = {}
        for(twitterUrl,twitterUrlCount) in TwitterUserUrl[twitterID].items():
            for(facebookUrl,facebookUrlCount) in FacebookUserUrl[facebookID].items():     
                if(twitterUrl == facebookUrl):
                    writedTwitterUrl[twitterUrl] = 1
                    writedFacebookUrl[facebookUrl] = 1
                    
                    if(not writedTwitterUrlRepeat.has_key(twitterUrl)):
                        writedTwitterUrlRepeat[twitterUrl] = 1
                    else:
                        writedTwitterUrlRepeat[twitterUrl] += 1
                        continue
                    if(not writedFacebookUrlRepeat.has_key(facebookUrl)):
                        writedFacebookUrlRepeat[facebookUrl] = 1
                    else:
                        writedFacebookUrlRepeat[facebookUrl] += 1
                        continue
                    
                    sameUrlCount += 1
                    fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(facebookUrl) + '\n')
                else:
                    posQuestion = twitterUrl.find('?')
                    posHashMark = twitterUrl.find('#')
                    twitterUrl2 = twitterUrl
                    twitterUrlLeft = ''
                    if(posQuestion > 0):
                        twitterUrl2 = twitterUrl[:posQuestion]
                        twitterUrlLeft = twitterUrl[posQuestion:]
                    elif(posHashMark > 0):
                        twitterUrl2 = twitterUrl[:posHashMark]
                        twitterUrlLeft = twitterUrl[posHashMark:]                        
                        
                    posQuestion2 = facebookUrl.find('?')
                    posHashMark2 = facebookUrl.find('#')
                    facebookUrl2 = facebookUrl
                    facebookUrlLest = ''
                    if(posQuestion2 > 0):
                        facebookUrl2 = facebookUrl[:posQuestion2]
                        facebookUrlLest = facebookUrl[posQuestion2:]
                    elif(posHashMark2 > 0):
                        facebookUrl2 = facebookUrl[:posHashMark2]
                        facebookUrlLest = facebookUrl[posHashMark2:]

                    if(twitterUrl2 == facebookUrl2):
                        isSame = 0
                        if(twitterUrlLeft != ''):
                            #medium=
                            if(twitterUrlLeft.find('source=') >0 or twitterUrlLeft.find('platform=') > 0 or twitterUrlLeft.find('ref=')>0):
                                isSame = 1
                        if(facebookUrlLest != ''):
                            if(facebookUrlLest.find('source=') >0 or facebookUrlLest.find('platform=') > 0 or facebookUrlLest.find('ref=')>0):
                                isSame = 1  
                        if(isSame == 0):
                            continue
                        writedTwitterUrl[twitterUrl] = 1
                        writedFacebookUrl[facebookUrl] = 1

                        
                        if(not writedTwitterUrlRepeat.has_key(twitterUrl2)):
                            writedTwitterUrlRepeat[twitterUrl2] = 1
                        else:
                            writedTwitterUrlRepeat[twitterUrl2] += 1
                            continue
                        if(not writedFacebookUrlRepeat.has_key(facebookUrl2)):
                            writedFacebookUrlRepeat[facebookUrl2] = 1
                        else:
                            writedFacebookUrlRepeat[facebookUrl2] += 1
                            continue
                        
                        sameUrlCount += 1
                        fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(facebookUrl) + '\n')  
                        
        for(twitterUrl,twitterUrlCount) in TwitterUserUrl[twitterID].items():
            if(not writedTwitterUrl.has_key(twitterUrl)):
                fout.write(data + '\t'  + str(twitterUrl) + '\t'  + str(0) + '\n')
        for(facebookUrl,facebookUrlCount) in FacebookUserUrl[facebookID].items(): 
            if(not writedFacebookUrl.has_key(facebookUrl)):
                fout.write(data + '\t'  + str(0) + '\t'  + str(facebookUrl) + '\n')

'''
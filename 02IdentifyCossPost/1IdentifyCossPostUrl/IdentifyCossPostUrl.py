# -*- coding: utf-8 -*-
# this is used to match the contents with same URLs of same users of  twitter facebook users in userSameUrlCountSelectUsers
# PS: this use the function: isSameUrl(url1,url2) in IdentifySameUrls.py

# input1: userSelectEnglishTimezone    # generated by 07UserSelection 
# twitterID #followr #twitterUrl #sameLongUrl FacebookID #likes #facebookUrl     howMatchUserID        twitterName       facebookName   timeZone 
# 109118967	3904208	41	    5	113525172018777	2464791	12	FacebookFromTwitterProfiles	jaimecamil	jaimecamil      -14400
# 62477022	244525	15	    7	192465074360	1724259	14	FacebookFromTwitterProfiles	andaadam	AndaAdamOfficial -18000
#   0           1       2           3           4         5     6                    7                   8                   9             10

# input2: expandDnsTwitterData
# shortURL                               longURL                                       status
# http://bit.ly/1Ux1bFx	https://amp.twimg.com/v/77996099-1089-4371-944d-3e863875fd7b	200
# http://www.warnerchannel.com	http://www.warnerchannel.com/co/	200

# input3: expandDnsFacebookData

# input4: FormatTwitterTweets
#    userId       TweetID            #RT #favorite #comment    date         isRT isRep      expandURL    #mentions #hashtage   text
#|::|14985126|::|714569507218456577|::|1|::|2|::|0|::|2016-03-28 21:47:01|::|0|::|0|::|http://bit.ly/1LammK9|::|0|::|0|::|What to https://t.co/WdNuNLJ0Mu|;;|
#|::|14985126|::|714520937341784064|::|2|::|3|::|0|::|2016-03-28 18:34:01|::|0|::|0|::|http://bit.ly/1o0Yy0R|::|0|::|0|::|When it https://t.co/ad5Go6wy7q https://t.co/N06Lnne6yE|;;|
#|::|19813909|::|674087130738528256|::|0|::|0|::|0|::|2015-12-08 04:44:30|::|0|::|0|::|http://bit.ly/1MZoGOY;	http://bit.ly/1TW21rz|::|0|::|0|::|https://t.co/myda1D6IiS Ant-Man on Blu-Ray https://t.co/cOcIZIXZ1U|;;|
#    0                  1              2    3    4               5           6    7            8                9    10        11   

# input5: FormatFacebookFeeds
# userId		feedID	#shares	#likes	#comments	created_time	    type	status_type	link	            name	description	message
#|::|94319190752|::|10153640474135753|::|3|::|7|::|7|::|2016-04-14 02:00:00|::|link|::|shared_story|::|http://www.patheos.com|::|Sex and|::|For the|::|Even if|;;|
#|::|94319190752|::|10153640287040753|::|0|::|5|::|1|::|2016-04-14 00:00:00|::|link|::|shared_story|::|http://www.patheos.com|::|Are Polytheists |::|Why is|::|Yvonne|;;|
#       0               1                2     3    4              5                   6          7              8                        9            10       11

# output: IdentifyCossPostUrl  # is used for Question2EffectIdeal, Question3PostAll, and experiments
# twUserID	twTweetID	fbUserID	fbFeedID  urlOrderNum #twRT #twFavorite	#twComment #fbReshare #fbLikes #fbComment timeDifference  twitterName facebookName 
# 19019298	7.14543E+17	37791069588	1.01541E+16	13	1	1	    0	        0	0	0	    -4	        IAmBiotech	IAmBiotech
# 13877002	7.15385E+17	72139486384	1.01541E+16	1	2	4	    0	        1	7	2	    -583	clarionledger	clarionledger
#   0              1                2             3             4       5       6           7           8       9       10           11               12            13

# output: IdentifyCossPostUrlRepeat  # is used for Question1Overlap
# this don't remove repeated tweet or feeds, for example, tA and tB in Twitter have same means and will match fC. this will generate result as below:
#  tA  fC
#  tB  fB

import urllib2
import urllib
import cookielib
import re
import datetime
import time
import sys
import os
import traceback
from urllib2 import HTTPError, Request, urlopen, URLError
import difflib
#import adodbapi
#import minjson

import IdentifySameUrls


def printTime(beginTime):
    endTime = datetime.datetime.now() #calculate time
    print ("------------consumed-----------time-----------begin-----------")
    print ("consumed time:" + str(endTime - beginTime) )
    print ("------------consumed-----------time-----------end-------------")

def readSelectUsers(inFile,TwitterSelectUser,FacebookSelectUser):
    fin = open(inFile) 
    count =0
    selectCount = 0
    for current in fin:
        count += 1
        data = current.replace('\n','')
        curL = data.split('\t')
        twitterID = curL[0]
        facebookID = curL[4]
        UtcOffset = int(curL[10])/3600
        TwitterSelectUser[twitterID] = UtcOffset
        FacebookSelectUser[facebookID] = UtcOffset
        
def readFormatTweets(inFile4,TwitterSelectUser,twitterExpandUrl,twUserTweetInfo,twitterOrFacebook):

    startTime = time.strptime('2016-03-15 00:00:00','%Y-%m-%d %H:%M:%S')
    #startTime = time.strptime('2016-04-13 00:00:00','%Y-%m-%d %H:%M:%S')  # needn't care about the start time 
    endTime = time.strptime('2016-04-15 00:00:00','%Y-%m-%d %H:%M:%S')    # the end time should be setted, because the most recent tweets have no retweets
    startTime1 = int(time.mktime(startTime))    
    endTime1 = int(time.mktime(endTime))        
    #outFile = outFile + lenInt(startTime.tm_mon) + lenInt(startTime.tm_mday) + '_' + lenInt(endTime.tm_mon) + lenInt(endTime.tm_mday)
    #fout2 = open("aaaaaa","w")
    
    fin = open(inFile4)
    # input4: FormatTwitterTweets
    #    userId       TweetID            #RT #favorite #comment    date         isRT isRep      expandURL    #mentions #hashtage   text
    #|::|14985126|::|714569507218456577|::|1|::|2|::|0|::|2016-03-28 21:47:01|::|0|::|0|::|http://bit.ly/1LammK9|::|0|::|0|::|What to https://t.co/WdNuNLJ0Mu|;;|
    #|::|14985126|::|714520937341784064|::|2|::|3|::|0|::|2016-03-28 18:34:01|::|0|::|0|::|http://bit.ly/1o0Yy0R|::|0|::|0|::|When it https://t.co/ad5Go6wy7q https://t.co/N06Lnne6yE|;;|
    #|::|29679737|::|720954857880961024|::|0|::|0|::|0|::|2016-04-15 12:40:07|::|0|::|1|::|null|::|1|::|0|::|@InnovativeTree It's just a guess. Audi A5 :-)|;;|
    #|::|19813909|::|674087130738528256|::|0|::|0|::|0|::|2015-12-08 04:44:30|::|0|::|0|::|http://bit.ly/1MZoGOY;	http://bit.ly/1TW21rz|::|0|::|0|::|https://t.co/myda1D6IiS Ant-Man on Blu-Ray https://t.co/cOcIZIXZ1U|;;|
    #    0                  1              2    3    4               5           6    7            8                9    10        11  
    # input4: FormatFacebookFeeds
    # userId		feedID	        #shares	#likes	#comments	created_time  type	status_type	link	            name	description	message
    #|::|94319190752|::|10153640474135753|::|3|::|7|::|7|::|2016-04-14 02:00:00|::|link|::|shared_story|::|http://www.patheos.com|::|Sex and|::|For the|::|Even if|;;|
    #|::|94319190752|::|10153640287040753|::|0|::|5|::|1|::|2016-04-14 00:00:00|::|link|::|shared_story|::|http://www.patheos.com|::|Are Polytheists |::|Why is|::|Yvonne|;;|
    #|::|94319190752|::|10153640182385753|::|10|::|29|::|5|::|2016-04-13 22:00:00|::|link|::|shared_story|::|http://www.patheos.com|::|The Church|::|In the|::|Has |;;|
    #       0               1                2     3    4              5             6          7                8                   9            10              11
    
    columnMark =  '|::|'
    rowMark = '|;;|\n'
    count =0
    for current in fin:
        data = current[4:-5]
        curL = data.split(columnMark)
        userId = curL[0]
        tweetId = curL[1]
        retweet = int(curL[2])
        favorite = int(curL[3])
        comment  = int(curL[4])
        createdTime2 = curL[5]
        isRT = curL[6]  # it is '0' or '1' for Twitter, and it is link, status or photo for Facebook
        shortUrl = curL[8]
        content = ""
        if(twitterOrFacebook == "twitter"):
            content = curL[11]
        elif(twitterOrFacebook == "facebook"):
            content = curL[9]  + " " + curL[10] + " " + curL[11]
        content = content.replace('\n',' ')
        content = content.replace('\r',' ')

        if( isRT == '1'):                                          #-----------------------retweet in Twitter-------------------------filter-----------------
            continue
        if(not TwitterSelectUser.has_key(userId) ):                #-----------------------not selected users-------------------------filter-----------------
            continue
        if (shortUrl == 'null'):                                   #-----------------------No Urls------------------------------------filter-----------------
            continue        
        if (shortUrl.find(";\t") > 0):                             #-----------------------has two short Urls--------------------------filter-----------------
            continue    # such as (http://bit.ly/1MZoGOY;	http://bit.ly/1TW21rz)
        if (not twitterExpandUrl.has_key(shortUrl)):               #-----------------------No expanded URLs----------------------------filter-----------------
            continue
        expandurl  = twitterExpandUrl[shortUrl]
        #fout2.write(userId + "\t"  +   shortUrl + "\t" + expandurl + "\n" )
        if(expandurl.find('twitter.com') >= 0):                    #-----------------------twitter Urls--------------------------------filter----------------- 
            continue   # only select the third websites
        if(expandurl.find('facebook.com') >= 0):                   #-----------------------facebook Urls-------------------------------filter----------------- 
            continue
        # ---------------------timezone-----------adjuct-----------------------------------begin-------------
        timeLag = TwitterSelectUser[userId]
        originalTime = datetime.datetime.strptime(createdTime2,"%Y-%m-%d %H:%M:%S")
        adjustTime = originalTime + datetime.timedelta(hours = timeLag)  
        createdTime = adjustTime.strftime("%Y-%m-%d %H:%M:%S")    
        # ---------------------timezone-----------adjuct------------------------------------end-------------
        
        gettedTime = time.strptime(createdTime,'%Y-%m-%d %H:%M:%S') # 2012-06-11 07:03:04
        gettedTime1 = int(time.mktime(gettedTime))
        if( not (gettedTime1 >= startTime1 and gettedTime1 <= endTime1)): 
            #print time.strftime("%Y-%m-%d %X",gettedTime)
            continue                                             #---------------------not selected period----------------------------filter----------------- 
        
        if(not twUserTweetInfo.has_key(userId)):
            twUserTweetInfo[userId] = {}
        if(not twUserTweetInfo[userId].has_key(tweetId)):
            twUserTweetInfo[userId][tweetId] = [expandurl,retweet,favorite,comment,createdTime,1,content]
        #else:
        #    twUserTweetInfo[userId][tweetId][5] += 1  # skip the repeated ones
    fin.close()
    print 'len(twUserTweetInfo):' + str(len(twUserTweetInfo))


def readUserPair(inFile,outFile,twUserTweetInfo,fbUserFeedInfo):
    #-----------avoid one match multiple 20160920----------------------begin-------------------
    tweetDict = {} # tweetDict[tweetId] = 1  # this is used to remove multiple match, i.e., one tweet match muliple feeds, or one feed match multple tweet
    feedDict = {}  # feedDict[feedId] = 1
    tweetFeedDict = {} # tweetFeedDict[tweetId + feedId] = content needed to write outFile
    #-----------avoid one match multiple 20160920----------------------end---------------------
       
    fin = open(inFile)   # IdentifySameUser
    # twitterID #followr #twitterUrl #sameLongUrl FacebookID #likes #facebookUrl     howMatchUserID        twitterName       facebookName   timeZone 
    # 109118967	3904208	41	    5	113525172018777	2464791	12	FacebookFromTwitterProfiles	jaimecamil	jaimecamil      -14400
    #   0           1       2           3           4         5     6                    7                   8                   9             10
    
    fout = open(outFile,'w')
    foutRepeat = open(outFile + 'Repeat','w')  # this used for Question1Overlap
    count =0
    selectCount = 0
    tweetCount = 0
    feedCount = 0
    for current in fin:
        count += 1
        if(count % 100 == 0):
            print count
        data = current.replace('\n','')
        curL = data.split('\t')
        twitterID = curL[0]
        facebookID = curL[4]
        follower = curL[1]
        likes = curL[5]
        twitterName = curL[8]
        facebookName = curL[9]
        

        if(not twUserTweetInfo.has_key(twitterID)): 
            continue
        if(not fbUserFeedInfo.has_key(facebookID)):
            continue
        
        tweetCount += len(twUserTweetInfo[twitterID])
        feedCount  += len(fbUserFeedInfo[facebookID])
        # twUserTweetInfo[userid][tweetId] = [expandurl,retweet,favorite,comment,createdTime,1,content]
        #                                          0       1      2         3       4        5    6
        urlOrderNum = 0
        for(tweetId,twitterUrlInfo) in twUserTweetInfo[twitterID].items():
            for(feedId,facebookUrlInfo) in fbUserFeedInfo[facebookID].items():   
                #if(int(twitterUrlInfo[5]) >= 2):        #-----------------------tweetId is repeated--------------------------filter-----------------
                #    continue
                #if(int(facebookUrlInfo[5]) >= 2):       #-----------------------feedId  is repeated--------------------------filter-----------------
                #    continue
                twExpandUrl = twitterUrlInfo[0]
                fbExpandUrl = facebookUrlInfo[0]
                
                isSameUrlAndWrite = 0
                if(twExpandUrl == fbExpandUrl):
                    urlOrderNum += 1
                    isSameUrlAndWrite = 1
                else:
                    (isSame,extractUrl) = IdentifySameUrls.isSameUrl(twExpandUrl,fbExpandUrl)
                    if(isSame == 1):
                        urlOrderNum += 1
                        isSameUrlAndWrite = 1
                if(isSameUrlAndWrite == 1):
                    date1 = time.strptime(twitterUrlInfo[4],'%Y-%m-%d %H:%M:%S')  # 2012-06-11 07:03:04  
                    date2 = time.strptime(facebookUrlInfo[4],'%Y-%m-%d %H:%M:%S') # 2012-06-11 07:03:04
                    
                    twCreatedTime=datetime.datetime(date1[0],date1[1],date1[2],date1[3],date1[4],date1[5])
                    fbCreatedTime=datetime.datetime(date2[0],date2[1],date2[2],date2[3],date2[4],date2[5])
                    
                    eclispedDay = (fbCreatedTime - twCreatedTime).days
                    timeDiffernce = (fbCreatedTime - twCreatedTime).seconds
                    timeDiffernce += eclispedDay*24*60*60 
                    timeDiffernce = timeDiffernce/60
                    #if ( abs(twitterUrlInfo[1] - facebookUrlInfo[1]) <= 10 ):  #----------difference between #RT and #Share <= n------------------filter-----------------
                    #    continue
                    #print timeDiffernce/60
                    '''
                    #		twUserID		twTweetID		fbUserID		fbFeedID                        urlOrderNum
                    fout.write(twitterID+'\t'+ str(twitterUrlInfo[0]) +'\t'+ str(facebookID) + '\t'+ str(facebookUrlInfo[0]) +'\t' + str(urlOrderNum) + '\t'+ 
                               #	#twRT				#twFavorite			#twComment		
                               str(twitterUrlInfo[1]) + '\t'  + str(twitterUrlInfo[2]) + '\t'  + str(twitterUrlInfo[3]) + '\t'  +
                               #	fbReshare			#fbLikes			#fbComment                   timeDifference
                               str(facebookUrlInfo[1]) + '\t' + str(facebookUrlInfo[2]) + '\t' + str(facebookUrlInfo[3]) + '\t' + str(timeDiffernce)+ '\t'+ 
                               str(twitterName)+ '\t'+str(facebookName)+'\n')                    
                    '''
                    #-----------avoid one match multiple 20160920----------------------begin-------------------
                    #tweetId = twitterUrlInfo[0]
                    #feedId = facebookUrlInfo[0]
                    if(not tweetDict.has_key(tweetId)):
                        tweetDict[tweetId] = 0
                    tweetDict[tweetId] += 1
                    if(not feedDict.has_key(feedId)):
                        feedDict[feedId] = 0
                    feedDict[feedId] += 1
                    writeContent = twitterID+'\t'+ str(tweetId) +'\t'+ str(facebookID) + '\t'+ str(feedId) +'\t' + str(urlOrderNum) + '\t'+ \
                               str(twitterUrlInfo[1]) + '\t'  + str(twitterUrlInfo[2]) + '\t'  + str(twitterUrlInfo[3]) + '\t'  + \
                               str(facebookUrlInfo[1]) + '\t' + str(facebookUrlInfo[2]) + '\t' + str(facebookUrlInfo[3]) + '\t' + str(timeDiffernce)+ '\t'+ \
                               str(twitterName)+ '\t'+str(facebookName) +'\n'
                               #str(twitterName)+ '\t'+str(facebookName) + '\t'+str(twitterUrlInfo[6]) + '\t'+str(facebookUrlInfo[6]) +'\n'
                    tweetFeedDict[tweetId + "," + feedId] = writeContent
                    #-----------avoid one match multiple 20160920----------------------end---------------------
                    selectCount += 1
    print "tweetCount:" + str(tweetCount) + ";;feedCount" + str(feedCount) + ";;selectCount:" + str(selectCount) + \
          ";;tweetDict:" + str(len(tweetDict))+ ";;feedDict:" + str(len(feedDict))
    #-----------avoid one match multiple 20160920----------------------begin-------------------
    for (u,v) in tweetFeedDict.items():
        uSplit = u.split(",")
        tweetId = uSplit[0]
        feedId = uSplit[1]
        
        foutRepeat.write(v) 
        if(tweetDict[tweetId] > 1):
            #print "tweetId:" + tweetId
            continue
        if( feedDict[feedId] > 1):
            #print "feedId:" + feedId
            continue
        fout.write(v) 
    #-----------avoid one match multiple 20160920----------------------end---------------------
                    
def main(argv):
    inFile = argv[1]   # IdentifySameUser 
    inFile2 = argv[2]  # expandDnsTwitterData
    inFile3 = argv[3]  # expandDnsFacebookData
    inFile4 = argv[4]  # FormatTwitterTweets
    inFile5 = argv[5]  # FormatFacebookFeeds
    outFile = argv[6]  # TweetFeedUrlMatch
    
    reload(sys)
    sys.setdefaultencoding('utf-8')
    beginTime = datetime.datetime.now() 


    TwitterSelectUser = {}  # TwitterSelectUser[userId]  = UtcOffset
    FacebookSelectUser = {} # FacebookSelectUser[userId] = UtcOffset
    readSelectUsers(inFile,TwitterSelectUser,FacebookSelectUser)
    
    twitterExpandUrl = {} # twitterExpandUrl[shortUrl] = expandUrl
    IdentifySameUrls.readExpandDns(inFile2,twitterExpandUrl)
    facebookExpandUrl = {} # facebookExpandUrl[shortUrl] = expandUrl
    IdentifySameUrls.readExpandDns(inFile3,facebookExpandUrl)
    
    twUserTweetInfo = {} # twUserTweetInfo[userid][tweetId] = [expandurl,retweet,favorite,comment,createdTime,1,content]
    twitterOrFacebook = "twitter"
    readFormatTweets(inFile4,TwitterSelectUser,twitterExpandUrl,twUserTweetInfo,twitterOrFacebook)

    fbUserFeedInfo = {} # fbUserFeedInfo[userid][feedId] = [expandurl,retweet,favorite,comment,createdTime,1,content]
    twitterOrFacebook = "facebook"
    readFormatTweets(inFile5,FacebookSelectUser,facebookExpandUrl,fbUserFeedInfo,twitterOrFacebook)    
    #readFormatTweets(inFile5, fbUserFeedInfo,facebookExpandUrl,TwitterSelectUser,FacebookSelectUser)
    
    readUserPair(inFile,outFile,twUserTweetInfo,fbUserFeedInfo)
    
    '''
    fout = open(outFile,'w')
    for (userId,expandUrlInfo) in twUserTweetInfo.items():
        for (expandUrl,urlInfo) in expandUrlInfo.items():
            fout.write(userId + "\t" + expandUrl+ "\t" + str(urlInfo[0])+ "\t" + str(urlInfo[1])+ "\t" + str(urlInfo[2])+ "\t" 
                       + str(urlInfo[3])+ "\t" + str(urlInfo[4])+ "\t" + str(urlInfo[5]) + "\n")
        
    ''' 

    '''
    url1 = 'http://www.theonion.com/article/report-freezers-healthy-choice-corporate-offices-p-52642?utm_medium=RSS&utm_campaign=feeds'
    url2 = identifySameUrls.clearUrlUtm(url1)
    print url1
    print url2
    '''


    '''
    startTime =  datetime.datetime.strptime("2014-05-14 01:16:39",'%Y-%m-%d %H:%M:%S')
    publishTime = datetime.datetime.strptime("2014-05-13 23:16:39",'%Y-%m-%d %H:%M:%S')
    eclispedDay = (publishTime - startTime).days
    print eclispedDay
    eclispedMinutes = int((publishTime - startTime).seconds/60)
    print eclispedMinutes
    eclispedMinutes += eclispedDay*24*60 
    print eclispedMinutes
    '''
    
    printTime(beginTime)       
    print "\a"
    print 'finish' 

    
if __name__ == "__main__":
    #Ö´main fuction
    main(sys.argv)
